{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminar operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torcheeg import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using \"cuda\" device\n"
     ]
    }
   ],
   "source": [
    "# verify GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using \\\"{}\\\" device\".format(device))\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THINGS-EEG2 (subset: single subject)**\n",
    "\n",
    "RSVP: time-efficient rapid serial visual presentation\n",
    "- 1 subject\n",
    "- 17 channels\n",
    "- 1 second recording 100 samples (10ms or 100Hz freq)\n",
    "- 1854 concepts\n",
    "- 16740 images\n",
    "- 82160 trials\n",
    "- 27 or 53 high level categories (overlapped and missing categories)\n",
    "\n",
    "Train:\n",
    "- 1654 concepts\n",
    "- 16540 images (10 images per concept)\n",
    "- 66160 trial (4 rep per image)\n",
    "\n",
    "Test:\n",
    "- 200 concepts\n",
    "- 200 images (1 image per concept)\n",
    "- 16000 trial (80 rep per image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path to the data\n",
    "data_path = '../data/THINGS-EEG2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_train_path = os.path.join(data_path, 'preprocessed_data', 'sub-' + '04', 'preprocessed_eeg_' + 'training' + '.npy')\n",
    "eeg_test_path = os.path.join(data_path, 'preprocessed_data', 'sub-' + '04', 'preprocessed_eeg_' + 'test' + '.npy')\n",
    "image_metadata_path = os.path.join(data_path, 'image_metadata/image_metadata.npy')\n",
    "category53_path = os.path.join(data_path, 'image_metadata/category53_longFormat.tsv')\n",
    "category27_mat_path = os.path.join(data_path, 'image_metadata/category_mat_manual.tsv')\n",
    "\n",
    "eeg_train = np.load(eeg_train_path, allow_pickle=True).item()\n",
    "eeg_test = np.load(eeg_test_path, allow_pickle=True).item()\n",
    "image_metadata = np.load(image_metadata_path, allow_pickle=True).item()\n",
    "category53 = pd.read_csv(category53_path, sep='\\t')\n",
    "category27_mat = pd.read_csv(category27_mat_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test_img_concepts', 'test_img_concepts_THINGS', 'test_img_files', 'train_img_files', 'train_img_concepts', 'train_img_concepts_THINGS'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>bird</th>\n",
       "      <th>body part</th>\n",
       "      <th>clothing</th>\n",
       "      <th>clothing accessory</th>\n",
       "      <th>container</th>\n",
       "      <th>dessert</th>\n",
       "      <th>drink</th>\n",
       "      <th>electronic device</th>\n",
       "      <th>food</th>\n",
       "      <th>...</th>\n",
       "      <th>musical instrument</th>\n",
       "      <th>office supply</th>\n",
       "      <th>part of car</th>\n",
       "      <th>plant</th>\n",
       "      <th>sports equipment</th>\n",
       "      <th>tool</th>\n",
       "      <th>toy</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>weapon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1854 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      animal  bird  body part  clothing  clothing accessory  container  \\\n",
       "0          1     0          0         0                   0          0   \n",
       "1          0     0          0         0                   0          0   \n",
       "2          0     0          0         0                   0          0   \n",
       "3          0     0          0         0                   0          0   \n",
       "4          0     0          0         0                   0          0   \n",
       "...      ...   ...        ...       ...                 ...        ...   \n",
       "1849       0     0          0         0                   0          0   \n",
       "1850       0     0          0         0                   0          0   \n",
       "1851       1     0          0         0                   0          0   \n",
       "1852       0     0          0         0                   0          0   \n",
       "1853       0     0          0         0                   0          0   \n",
       "\n",
       "      dessert  drink  electronic device  food  ...  musical instrument  \\\n",
       "0           0      0                  0     0  ...                   0   \n",
       "1           0      0                  0     0  ...                   0   \n",
       "2           0      0                  0     0  ...                   1   \n",
       "3           0      0                  0     0  ...                   0   \n",
       "4           0      0                  1     0  ...                   0   \n",
       "...       ...    ...                ...   ...  ...                 ...   \n",
       "1849        0      0                  0     0  ...                   0   \n",
       "1850        0      0                  0     1  ...                   0   \n",
       "1851        0      0                  0     0  ...                   0   \n",
       "1852        0      0                  0     0  ...                   0   \n",
       "1853        0      0                  0     1  ...                   0   \n",
       "\n",
       "      office supply  part of car  plant  sports equipment  tool  toy  \\\n",
       "0                 0            0      0                 0     0    0   \n",
       "1                 0            0      0                 0     0    0   \n",
       "2                 0            0      0                 0     0    0   \n",
       "3                 0            0      0                 0     0    0   \n",
       "4                 0            0      0                 0     0    0   \n",
       "...             ...          ...    ...               ...   ...  ...   \n",
       "1849              0            0      0                 0     0    0   \n",
       "1850              0            0      0                 0     0    0   \n",
       "1851              0            0      0                 0     0    0   \n",
       "1852              0            0      0                 0     0    0   \n",
       "1853              0            0      0                 0     0    0   \n",
       "\n",
       "      vegetable  vehicle  weapon  \n",
       "0             0        0       0  \n",
       "1             0        0       0  \n",
       "2             0        0       0  \n",
       "3             0        0       0  \n",
       "4             0        0       0  \n",
       "...         ...      ...     ...  \n",
       "1849          0        0       0  \n",
       "1850          0        0       0  \n",
       "1851          0        0       0  \n",
       "1852          0        0       0  \n",
       "1853          1        0       0  \n",
       "\n",
       "[1854 rows x 27 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category27_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EEG signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16540, 4, 17, 100)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_train['preprocessed_eeg_data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_channels = 17\n",
    "# n_times = 100\n",
    "# n_classes = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66160, 17, 100)\n",
      "(16000, 17, 100)\n"
     ]
    }
   ],
   "source": [
    "eeg_train_reshaped = eeg_train['preprocessed_eeg_data'].reshape((-1, 17, 100))\n",
    "eeg_test_reshaped = eeg_test['preprocessed_eeg_data'].reshape((-1, 17, 100))\n",
    "\n",
    "print(eeg_train_reshaped.shape)\n",
    "print(eeg_test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['test_img_concepts', 'test_img_concepts_THINGS', 'test_img_files', 'train_img_files', 'train_img_concepts', 'train_img_concepts_THINGS'])\n",
      "['00001_aardvark', '00001_aardvark', '00001_aardvark', '00001_aardvark', '00001_aardvark']\n",
      "['00001_aardvark', '00001_aardvark', '00001_aardvark', '00001_aardvark', '00001_aardvark']\n",
      "['aardvark_01b.jpg', 'aardvark_02s.jpg', 'aardvark_03s.jpg', 'aardvark_04s.jpg', 'aardvark_05s.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(image_metadata.keys())\n",
    "print(image_metadata['train_img_concepts'][:5])\n",
    "print(image_metadata['train_img_concepts_THINGS'][:5])\n",
    "print(image_metadata['train_img_files'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of files names in zip\n",
    "def get_concepts(partition):\n",
    "    path_tmp = os.path.join(data_path, 'image_set', f'{partition}_images.zip')\n",
    "\n",
    "    with ZipFile(path_tmp, 'r') as zipObj:\n",
    "        # Get list of files names in zip\n",
    "        files_list_tmp = zipObj.namelist()\n",
    "\n",
    "    files_list_tmp.sort()\n",
    "    concepts_tmp = ['_'.join(elem.split('/')[2].split('_')[: -1]) for elem in files_list_tmp if elem.endswith('/') == False]\n",
    "\n",
    "    concepts_tmp = np.repeat(concepts_tmp, 4 if partition == 'training' else 80)\n",
    "\n",
    "    return concepts_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66160\n",
      "16000\n"
     ]
    }
   ],
   "source": [
    "concepts_train = get_concepts('training')\n",
    "concepts_test = get_concepts('test')\n",
    "\n",
    "print(len(concepts_train))\n",
    "print(len(concepts_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concepts\n",
    "concepts_train_int = np.repeat(np.array(range(1654)), 40)\n",
    "concepts_test_int = np.repeat(np.array(range(200)), 80)\n",
    "\n",
    "concepts_test_dict = dict(zip(concepts_test_int, concepts_test)) # dictionary with concepts\n",
    "concepts_train_dict = dict(zip(concepts_train_int, concepts_train)) # dictionary with concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>concept_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accordion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acorn</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           concept  concept_ID\n",
       "0         aardvark           0\n",
       "1           abacus           1\n",
       "2        accordion           2\n",
       "3            acorn           3\n",
       "4  air_conditioner           4"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concept df\n",
    "concepts = sorted(list(set(concepts_train)) + list(set(concepts_test)))\n",
    "concepts_df = pd.DataFrame({'concept': concepts})\n",
    "concepts_df['concept_ID'] = concepts_df.index\n",
    "concepts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_ID</th>\n",
       "      <th>category27</th>\n",
       "      <th>category27_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[animal]</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[home decor]</td>\n",
       "      <td>[12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[musical instrument]</td>\n",
       "      <td>[17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[electronic device]</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[furniture]</td>\n",
       "      <td>[11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   concept_ID            category27 category27_ID\n",
       "0           0              [animal]           [0]\n",
       "1           1          [home decor]          [12]\n",
       "2           2  [musical instrument]          [17]\n",
       "3           4   [electronic device]           [8]\n",
       "4           5           [furniture]          [11]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category27 df\n",
    "category27_df = category27_mat[category27_mat==1].stack().reset_index().drop(0, axis=1)\n",
    "category27_df.columns = ['concept_ID', 'category27']\n",
    "category27_df.sort_values(by=['category27'], inplace=True)\n",
    "category27_df['category27_ID'] = pd.factorize(category27_df['category27'])[0]\n",
    "category27_df = category27_df.groupby('concept_ID').agg({'category27': lambda x: list(x), 'category27_ID': lambda x: list(x)}).reset_index()\n",
    "category27_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>category53</th>\n",
       "      <th>category53_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>[animal, mammal]</td>\n",
       "      <td>[0, 31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>[home decor]</td>\n",
       "      <td>[25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accordion</td>\n",
       "      <td>[musical instrument]</td>\n",
       "      <td>[33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>[electronic device, home appliance]</td>\n",
       "      <td>[13, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_mattress</td>\n",
       "      <td>[furniture]</td>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           concept                           category53 category53_ID\n",
       "0         aardvark                     [animal, mammal]       [0, 31]\n",
       "1           abacus                         [home decor]          [25]\n",
       "2        accordion                 [musical instrument]          [33]\n",
       "3  air_conditioner  [electronic device, home appliance]      [13, 24]\n",
       "4     air_mattress                          [furniture]          [19]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category53 df\n",
    "category53_df = category53.drop(columns='Word')\n",
    "category53_df.rename(columns={'category': 'category53', 'uniqueID': 'concept'}, inplace=True)\n",
    "category53_df.sort_values(by=['category53'], inplace=True)\n",
    "category53_df['category53_ID'] = pd.factorize(category53_df['category53'])[0]\n",
    "category53_df = category53_df.groupby('concept').agg({'category53': lambda x: list(x), 'category53_ID': lambda x: list(x)}).reset_index()\n",
    "category53_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept</th>\n",
       "      <th>concept_ID</th>\n",
       "      <th>category27</th>\n",
       "      <th>category27_ID</th>\n",
       "      <th>category53</th>\n",
       "      <th>category53_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>0</td>\n",
       "      <td>[animal]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[animal, mammal]</td>\n",
       "      <td>[0, 31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>1</td>\n",
       "      <td>[home decor]</td>\n",
       "      <td>[12]</td>\n",
       "      <td>[home decor]</td>\n",
       "      <td>[25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accordion</td>\n",
       "      <td>2</td>\n",
       "      <td>[musical instrument]</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[musical instrument]</td>\n",
       "      <td>[33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acorn</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>4</td>\n",
       "      <td>[electronic device]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[electronic device, home appliance]</td>\n",
       "      <td>[13, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>yoke</td>\n",
       "      <td>1849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>yolk</td>\n",
       "      <td>1850</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>zebra</td>\n",
       "      <td>1851</td>\n",
       "      <td>[animal]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[animal, mammal]</td>\n",
       "      <td>[0, 31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>zipper</td>\n",
       "      <td>1852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[fastener]</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>1853</td>\n",
       "      <td>[food, vegetable]</td>\n",
       "      <td>[9, 24]</td>\n",
       "      <td>[food, vegetable]</td>\n",
       "      <td>[16, 48]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1854 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              concept  concept_ID            category27 category27_ID  \\\n",
       "0            aardvark           0              [animal]           [0]   \n",
       "1              abacus           1          [home decor]          [12]   \n",
       "2           accordion           2  [musical instrument]          [17]   \n",
       "3               acorn           3                   NaN           NaN   \n",
       "4     air_conditioner           4   [electronic device]           [8]   \n",
       "...               ...         ...                   ...           ...   \n",
       "1849             yoke        1849                   NaN           NaN   \n",
       "1850             yolk        1850                [food]           [9]   \n",
       "1851            zebra        1851              [animal]           [0]   \n",
       "1852           zipper        1852                   NaN           NaN   \n",
       "1853         zucchini        1853     [food, vegetable]       [9, 24]   \n",
       "\n",
       "                               category53 category53_ID  \n",
       "0                        [animal, mammal]       [0, 31]  \n",
       "1                            [home decor]          [25]  \n",
       "2                    [musical instrument]          [33]  \n",
       "3                                     NaN           NaN  \n",
       "4     [electronic device, home appliance]      [13, 24]  \n",
       "...                                   ...           ...  \n",
       "1849                                  NaN           NaN  \n",
       "1850                               [food]          [16]  \n",
       "1851                     [animal, mammal]       [0, 31]  \n",
       "1852                           [fastener]          [15]  \n",
       "1853                    [food, vegetable]      [16, 48]  \n",
       "\n",
       "[1854 rows x 6 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with the concepts and their categories\n",
    "boh_df = pd.merge(left=concepts_df, right=category27_df, on='concept_ID', how='left')\n",
    "boh_df = pd.merge(left=boh_df, right=category53_df, on='concept', how='left')\n",
    "boh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    993\n",
       "NaN    559\n",
       "2.0    276\n",
       "3.0     26\n",
       "Name: category27, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boh_df['category27'].str.len().value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    784\n",
       "2.0    476\n",
       "NaN    406\n",
       "3.0    140\n",
       "4.0     42\n",
       "5.0      5\n",
       "6.0      1\n",
       "Name: category53, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boh_df['category53'].str.len().value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEGNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test partition 200 classes\n",
    "- sub01 accuracy 20%\n",
    "- sub02 accuracy 15%\n",
    "- sub03 accuracy 25%\n",
    "- sub04 accuracy 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters and model\n",
    "\n",
    "model = models.EEGNet(chunk_size=100, num_electrodes=17, num_classes=200).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12000, 17, 100), (4000, 17, 100))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split\n",
    "len(eeg_test_reshaped)/200\n",
    "\n",
    "x_train_prova = []\n",
    "y_train_prova = []\n",
    "x_val_prova = []\n",
    "y_val_prova = []\n",
    "\n",
    "for i in range(0,80):\n",
    "    if i < 20:\n",
    "        x_val_prova.extend(eeg_test_reshaped[i::80])\n",
    "        y_val_prova.extend(concepts_test_int[i::80])\n",
    "    else:\n",
    "        x_train_prova.extend(eeg_test_reshaped[i::80])\n",
    "        y_train_prova.extend(concepts_test_int[i::80])\n",
    "\n",
    "x_train_prova = np.array(x_train_prova)\n",
    "x_val_prova = np.array(x_val_prova)\n",
    "y_train_prova = np.array(y_train_prova)\n",
    "y_val_prova = np.array(y_val_prova)\n",
    "\n",
    "x_train_prova.shape, x_val_prova.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "  def __init__(self, X_train, y_train):\n",
    "    self.X = torch.from_numpy(X_train.astype(np.float32)) # convert float64 to float32\n",
    "    self.y = torch.from_numpy(y_train).type(torch.LongTensor) # convert float64 to Long\n",
    "    self.len = self.X.shape[0]\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.y[index]\n",
    "  \n",
    "  def __len__(self):\n",
    "    return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = Data(x_train_prova, y_train_prova)\n",
    "data_val = Data(x_val_prova, y_val_prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " ...]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(iter(data_train))\n",
    "# iter(data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m data_train \u001b[39m=\u001b[39m Data(x_train_prova, y_train_prova)\n\u001b[0;32m      3\u001b[0m data_val \u001b[39m=\u001b[39m Data(x_val_prova, y_val_prova)\n\u001b[1;32m----> 5\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(data_train, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(data_val, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "# dataset and dataloader\n",
    "data_train = Data(x_train_prova, y_train_prova)\n",
    "data_val = Data(x_val_prova, y_val_prova)\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(data_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        X = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "\n",
    "        X = X.reshape(batch_size, 1, 17, 100)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            loss, current = loss.item(), batch_idx * len(X)\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def valid(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    val_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X = batch[0].to(device)\n",
    "            y = batch[1].to(device)\n",
    "\n",
    "            X = X.reshape(batch_size, 1, 17, 100)\n",
    "\n",
    "            pred = model(X)\n",
    "            val_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    val_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Val accuracy: {(100*correct):>0.1f}%, Val avg loss: {val_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Epoch 1 ---------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy: 2.8%, Val avg loss: 4.905233 \n",
      "\n",
      "------------ Epoch 2 ---------------\n",
      "Val accuracy: 5.9%, Val avg loss: 4.605338 \n",
      "\n",
      "------------ Epoch 3 ---------------\n",
      "Val accuracy: 6.7%, Val avg loss: 4.453997 \n",
      "\n",
      "------------ Epoch 4 ---------------\n",
      "Val accuracy: 9.4%, Val avg loss: 4.339848 \n",
      "\n",
      "------------ Epoch 5 ---------------\n",
      "Val accuracy: 10.0%, Val avg loss: 4.251158 \n",
      "\n",
      "------------ Epoch 6 ---------------\n",
      "Val accuracy: 11.5%, Val avg loss: 4.189923 \n",
      "\n",
      "------------ Epoch 7 ---------------\n",
      "Val accuracy: 12.4%, Val avg loss: 4.144713 \n",
      "\n",
      "------------ Epoch 8 ---------------\n",
      "Val accuracy: 12.2%, Val avg loss: 4.081394 \n",
      "\n",
      "------------ Epoch 9 ---------------\n",
      "Val accuracy: 13.1%, Val avg loss: 4.056725 \n",
      "\n",
      "------------ Epoch 10 ---------------\n",
      "Val accuracy: 12.7%, Val avg loss: 4.042118 \n",
      "\n",
      "------------ Epoch 11 ---------------\n",
      "Val accuracy: 13.6%, Val avg loss: 4.022032 \n",
      "\n",
      "------------ Epoch 12 ---------------\n",
      "Val accuracy: 14.1%, Val avg loss: 4.012230 \n",
      "\n",
      "------------ Epoch 13 ---------------\n",
      "Val accuracy: 14.3%, Val avg loss: 3.972534 \n",
      "\n",
      "------------ Epoch 14 ---------------\n",
      "Val accuracy: 14.2%, Val avg loss: 3.969154 \n",
      "\n",
      "------------ Epoch 15 ---------------\n",
      "Val accuracy: 13.4%, Val avg loss: 3.964015 \n",
      "\n",
      "------------ Epoch 16 ---------------\n",
      "Val accuracy: 14.4%, Val avg loss: 3.926499 \n",
      "\n",
      "------------ Epoch 17 ---------------\n",
      "Val accuracy: 14.9%, Val avg loss: 3.927060 \n",
      "\n",
      "------------ Epoch 18 ---------------\n",
      "Val accuracy: 14.6%, Val avg loss: 3.932419 \n",
      "\n",
      "------------ Epoch 19 ---------------\n",
      "Val accuracy: 15.0%, Val avg loss: 3.913558 \n",
      "\n",
      "------------ Epoch 20 ---------------\n",
      "Val accuracy: 14.6%, Val avg loss: 3.904003 \n",
      "\n",
      "------------ Epoch 21 ---------------\n",
      "Val accuracy: 15.4%, Val avg loss: 3.890239 \n",
      "\n",
      "------------ Epoch 22 ---------------\n",
      "Val accuracy: 16.1%, Val avg loss: 3.864564 \n",
      "\n",
      "------------ Epoch 23 ---------------\n",
      "Val accuracy: 15.2%, Val avg loss: 3.869253 \n",
      "\n",
      "------------ Epoch 24 ---------------\n",
      "Val accuracy: 16.4%, Val avg loss: 3.830568 \n",
      "\n",
      "------------ Epoch 25 ---------------\n",
      "Val accuracy: 15.5%, Val avg loss: 3.854290 \n",
      "\n",
      "------------ Epoch 26 ---------------\n",
      "Val accuracy: 15.9%, Val avg loss: 3.863745 \n",
      "\n",
      "------------ Epoch 27 ---------------\n",
      "Val accuracy: 15.7%, Val avg loss: 3.854878 \n",
      "\n",
      "------------ Epoch 28 ---------------\n",
      "Val accuracy: 16.4%, Val avg loss: 3.833096 \n",
      "\n",
      "------------ Epoch 29 ---------------\n",
      "Val accuracy: 16.8%, Val avg loss: 3.836442 \n",
      "\n",
      "------------ Epoch 30 ---------------\n",
      "Val accuracy: 16.3%, Val avg loss: 3.813673 \n",
      "\n",
      "------------ Epoch 31 ---------------\n",
      "Val accuracy: 17.0%, Val avg loss: 3.788044 \n",
      "\n",
      "------------ Epoch 32 ---------------\n",
      "Val accuracy: 17.5%, Val avg loss: 3.817786 \n",
      "\n",
      "------------ Epoch 33 ---------------\n",
      "Val accuracy: 17.8%, Val avg loss: 3.790020 \n",
      "\n",
      "------------ Epoch 34 ---------------\n",
      "Val accuracy: 17.1%, Val avg loss: 3.815639 \n",
      "\n",
      "------------ Epoch 35 ---------------\n",
      "Val accuracy: 18.5%, Val avg loss: 3.763598 \n",
      "\n",
      "------------ Epoch 36 ---------------\n",
      "Val accuracy: 18.5%, Val avg loss: 3.774070 \n",
      "\n",
      "------------ Epoch 37 ---------------\n",
      "Val accuracy: 18.4%, Val avg loss: 3.795791 \n",
      "\n",
      "------------ Epoch 38 ---------------\n",
      "Val accuracy: 17.7%, Val avg loss: 3.784087 \n",
      "\n",
      "------------ Epoch 39 ---------------\n",
      "Val accuracy: 16.1%, Val avg loss: 3.841228 \n",
      "\n",
      "------------ Epoch 40 ---------------\n",
      "Val accuracy: 18.4%, Val avg loss: 3.768401 \n",
      "\n",
      "------------ Epoch 41 ---------------\n",
      "Val accuracy: 18.3%, Val avg loss: 3.747480 \n",
      "\n",
      "------------ Epoch 42 ---------------\n",
      "Val accuracy: 17.5%, Val avg loss: 3.765612 \n",
      "\n",
      "------------ Epoch 43 ---------------\n",
      "Val accuracy: 17.5%, Val avg loss: 3.755127 \n",
      "\n",
      "------------ Epoch 44 ---------------\n",
      "Val accuracy: 18.6%, Val avg loss: 3.756942 \n",
      "\n",
      "------------ Epoch 45 ---------------\n",
      "Val accuracy: 18.4%, Val avg loss: 3.752184 \n",
      "\n",
      "------------ Epoch 46 ---------------\n",
      "Val accuracy: 18.2%, Val avg loss: 3.744883 \n",
      "\n",
      "------------ Epoch 47 ---------------\n",
      "Val accuracy: 17.7%, Val avg loss: 3.749209 \n",
      "\n",
      "------------ Epoch 48 ---------------\n",
      "Val accuracy: 19.4%, Val avg loss: 3.722234 \n",
      "\n",
      "------------ Epoch 49 ---------------\n",
      "Val accuracy: 19.6%, Val avg loss: 3.720726 \n",
      "\n",
      "------------ Epoch 50 ---------------\n",
      "Val accuracy: 18.3%, Val avg loss: 3.721468 \n",
      "\n",
      "------------ Epoch 51 ---------------\n",
      "Val accuracy: 18.6%, Val avg loss: 3.737296 \n",
      "\n",
      "------------ Epoch 52 ---------------\n",
      "Val accuracy: 18.6%, Val avg loss: 3.726822 \n",
      "\n",
      "------------ Epoch 53 ---------------\n",
      "Val accuracy: 18.6%, Val avg loss: 3.755808 \n",
      "\n",
      "------------ Epoch 54 ---------------\n",
      "Val accuracy: 19.3%, Val avg loss: 3.702790 \n",
      "\n",
      "------------ Epoch 55 ---------------\n",
      "Val accuracy: 17.0%, Val avg loss: 3.760911 \n",
      "\n",
      "------------ Epoch 56 ---------------\n",
      "Val accuracy: 19.0%, Val avg loss: 3.695403 \n",
      "\n",
      "------------ Epoch 57 ---------------\n",
      "Val accuracy: 19.2%, Val avg loss: 3.696495 \n",
      "\n",
      "------------ Epoch 58 ---------------\n",
      "Val accuracy: 19.2%, Val avg loss: 3.682638 \n",
      "\n",
      "------------ Epoch 59 ---------------\n",
      "Val accuracy: 18.9%, Val avg loss: 3.720255 \n",
      "\n",
      "------------ Epoch 60 ---------------\n",
      "Val accuracy: 18.3%, Val avg loss: 3.750596 \n",
      "\n",
      "------------ Epoch 61 ---------------\n",
      "Val accuracy: 19.7%, Val avg loss: 3.707602 \n",
      "\n",
      "------------ Epoch 62 ---------------\n",
      "Val accuracy: 19.7%, Val avg loss: 3.697912 \n",
      "\n",
      "------------ Epoch 63 ---------------\n",
      "Val accuracy: 18.1%, Val avg loss: 3.706244 \n",
      "\n",
      "------------ Epoch 64 ---------------\n",
      "Val accuracy: 19.9%, Val avg loss: 3.675769 \n",
      "\n",
      "------------ Epoch 65 ---------------\n",
      "Val accuracy: 20.5%, Val avg loss: 3.675567 \n",
      "\n",
      "------------ Epoch 66 ---------------\n",
      "Val accuracy: 19.5%, Val avg loss: 3.672769 \n",
      "\n",
      "------------ Epoch 67 ---------------\n",
      "Val accuracy: 19.1%, Val avg loss: 3.700920 \n",
      "\n",
      "------------ Epoch 68 ---------------\n",
      "Val accuracy: 19.5%, Val avg loss: 3.711257 \n",
      "\n",
      "------------ Epoch 69 ---------------\n",
      "Val accuracy: 20.3%, Val avg loss: 3.661981 \n",
      "\n",
      "------------ Epoch 70 ---------------\n",
      "Val accuracy: 18.5%, Val avg loss: 3.760658 \n",
      "\n",
      "------------ Epoch 71 ---------------\n",
      "Val accuracy: 19.8%, Val avg loss: 3.661660 \n",
      "\n",
      "------------ Epoch 72 ---------------\n",
      "Val accuracy: 17.3%, Val avg loss: 3.760793 \n",
      "\n",
      "------------ Epoch 73 ---------------\n",
      "Val accuracy: 18.7%, Val avg loss: 3.726443 \n",
      "\n",
      "------------ Epoch 74 ---------------\n",
      "Val accuracy: 19.4%, Val avg loss: 3.695961 \n",
      "\n",
      "------------ Epoch 75 ---------------\n",
      "Val accuracy: 19.0%, Val avg loss: 3.691006 \n",
      "\n",
      "------------ Epoch 76 ---------------\n",
      "Val accuracy: 19.1%, Val avg loss: 3.683525 \n",
      "\n",
      "------------ Epoch 77 ---------------\n",
      "Val accuracy: 19.6%, Val avg loss: 3.677016 \n",
      "\n",
      "------------ Epoch 78 ---------------\n",
      "Val accuracy: 17.7%, Val avg loss: 3.711810 \n",
      "\n",
      "------------ Epoch 79 ---------------\n",
      "Val accuracy: 18.9%, Val avg loss: 3.733155 \n",
      "\n",
      "------------ Epoch 80 ---------------\n",
      "Val accuracy: 20.0%, Val avg loss: 3.693148 \n",
      "\n",
      "------------ Epoch 81 ---------------\n",
      "Val accuracy: 16.7%, Val avg loss: 3.761967 \n",
      "\n",
      "------------ Epoch 82 ---------------\n",
      "Val accuracy: 20.4%, Val avg loss: 3.660277 \n",
      "\n",
      "------------ Epoch 83 ---------------\n",
      "Val accuracy: 15.3%, Val avg loss: 3.841265 \n",
      "\n",
      "------------ Epoch 84 ---------------\n",
      "Val accuracy: 18.9%, Val avg loss: 3.690693 \n",
      "\n",
      "------------ Epoch 85 ---------------\n",
      "Val accuracy: 20.0%, Val avg loss: 3.650962 \n",
      "\n",
      "------------ Epoch 86 ---------------\n",
      "Val accuracy: 19.9%, Val avg loss: 3.659628 \n",
      "\n",
      "------------ Epoch 87 ---------------\n",
      "Val accuracy: 18.8%, Val avg loss: 3.723493 \n",
      "\n",
      "------------ Epoch 88 ---------------\n",
      "Val accuracy: 19.1%, Val avg loss: 3.696363 \n",
      "\n",
      "------------ Epoch 89 ---------------\n",
      "Val accuracy: 19.3%, Val avg loss: 3.706661 \n",
      "\n",
      "------------ Epoch 90 ---------------\n",
      "Val accuracy: 16.2%, Val avg loss: 3.804232 \n",
      "\n",
      "------------ Epoch 91 ---------------\n",
      "Val accuracy: 19.4%, Val avg loss: 3.659793 \n",
      "\n",
      "------------ Epoch 92 ---------------\n",
      "Val accuracy: 19.4%, Val avg loss: 3.706436 \n",
      "\n",
      "------------ Epoch 93 ---------------\n",
      "Val accuracy: 19.2%, Val avg loss: 3.677836 \n",
      "\n",
      "------------ Epoch 94 ---------------\n",
      "Val accuracy: 20.1%, Val avg loss: 3.651030 \n",
      "\n",
      "------------ Epoch 95 ---------------\n",
      "Val accuracy: 20.5%, Val avg loss: 3.657965 \n",
      "\n",
      "------------ Epoch 96 ---------------\n",
      "Val accuracy: 14.9%, Val avg loss: 3.799348 \n",
      "\n",
      "------------ Epoch 97 ---------------\n",
      "Val accuracy: 20.1%, Val avg loss: 3.658468 \n",
      "\n",
      "------------ Epoch 98 ---------------\n",
      "Val accuracy: 19.2%, Val avg loss: 3.665098 \n",
      "\n",
      "------------ Epoch 99 ---------------\n",
      "Val accuracy: 20.0%, Val avg loss: 3.641812 \n",
      "\n",
      "------------ Epoch 100 ---------------\n",
      "Val accuracy: 18.6%, Val avg loss: 3.682567 \n",
      "\n",
      "------------ Epoch 101 ---------------\n",
      "Val accuracy: 19.5%, Val avg loss: 3.673037 \n",
      "\n",
      "------------ Epoch 102 ---------------\n",
      "Val accuracy: 17.8%, Val avg loss: 3.724581 \n",
      "\n",
      "------------ Epoch 103 ---------------\n",
      "Val accuracy: 18.8%, Val avg loss: 3.716617 \n",
      "\n",
      "------------ Epoch 104 ---------------\n",
      "Val accuracy: 13.0%, Val avg loss: 3.911863 \n",
      "\n",
      "------------ Epoch 105 ---------------\n",
      "Val accuracy: 20.5%, Val avg loss: 3.678045 \n",
      "\n",
      "------------ Epoch 106 ---------------\n",
      "Val accuracy: 21.8%, Val avg loss: 3.618755 \n",
      "\n",
      "------------ Epoch 107 ---------------\n",
      "Val accuracy: 20.4%, Val avg loss: 3.655260 \n",
      "\n",
      "------------ Epoch 108 ---------------\n",
      "Val accuracy: 19.5%, Val avg loss: 3.701418 \n",
      "\n",
      "------------ Epoch 109 ---------------\n",
      "Val accuracy: 19.2%, Val avg loss: 3.720879 \n",
      "\n",
      "------------ Epoch 110 ---------------\n",
      "Val accuracy: 19.1%, Val avg loss: 3.682984 \n",
      "\n",
      "------------ Epoch 111 ---------------\n",
      "Val accuracy: 19.3%, Val avg loss: 3.727716 \n",
      "\n",
      "------------ Epoch 112 ---------------\n",
      "Val accuracy: 15.4%, Val avg loss: 3.806506 \n",
      "\n",
      "------------ Epoch 113 ---------------\n",
      "Val accuracy: 19.8%, Val avg loss: 3.701091 \n",
      "\n",
      "------------ Epoch 114 ---------------\n",
      "Val accuracy: 19.6%, Val avg loss: 3.650065 \n",
      "\n",
      "------------ Epoch 115 ---------------\n",
      "Val accuracy: 20.3%, Val avg loss: 3.644956 \n",
      "\n",
      "------------ Epoch 116 ---------------\n",
      "Val accuracy: 14.2%, Val avg loss: 3.859395 \n",
      "\n",
      "------------ Epoch 117 ---------------\n",
      "Val accuracy: 19.5%, Val avg loss: 3.691432 \n",
      "\n",
      "------------ Epoch 118 ---------------\n",
      "Val accuracy: 17.2%, Val avg loss: 3.694164 \n",
      "\n",
      "------------ Epoch 119 ---------------\n",
      "Val accuracy: 19.7%, Val avg loss: 3.663446 \n",
      "\n",
      "------------ Epoch 120 ---------------\n",
      "Val accuracy: 19.9%, Val avg loss: 3.669225 \n",
      "\n",
      "------------ Epoch 121 ---------------\n",
      "Val accuracy: 20.0%, Val avg loss: 3.636787 \n",
      "\n",
      "------------ Epoch 122 ---------------\n",
      "Val accuracy: 18.9%, Val avg loss: 3.702727 \n",
      "\n",
      "------------ Epoch 123 ---------------\n",
      "Val accuracy: 19.8%, Val avg loss: 3.669662 \n",
      "\n",
      "------------ Epoch 124 ---------------\n",
      "Val accuracy: 18.6%, Val avg loss: 3.654582 \n",
      "\n",
      "------------ Epoch 125 ---------------\n",
      "Val accuracy: 19.4%, Val avg loss: 3.655580 \n",
      "\n",
      "------------ Epoch 126 ---------------\n",
      "Val accuracy: 20.6%, Val avg loss: 3.654558 \n",
      "\n",
      "------------ Epoch 127 ---------------\n",
      "Val accuracy: 20.0%, Val avg loss: 3.674122 \n",
      "\n",
      "------------ Epoch 128 ---------------\n",
      "Val accuracy: 18.0%, Val avg loss: 3.686103 \n",
      "\n",
      "------------ Epoch 129 ---------------\n",
      "Val accuracy: 20.4%, Val avg loss: 3.648766 \n",
      "\n",
      "------------ Epoch 130 ---------------\n",
      "Val accuracy: 20.0%, Val avg loss: 3.668112 \n",
      "\n",
      "------------ Epoch 131 ---------------\n",
      "Val accuracy: 19.2%, Val avg loss: 3.690648 \n",
      "\n",
      "------------ Epoch 132 ---------------\n",
      "Val accuracy: 21.4%, Val avg loss: 3.602643 \n",
      "\n",
      "------------ Epoch 133 ---------------\n",
      "Val accuracy: 19.6%, Val avg loss: 3.673348 \n",
      "\n",
      "------------ Epoch 134 ---------------\n",
      "Val accuracy: 19.2%, Val avg loss: 3.653469 \n",
      "\n",
      "------------ Epoch 135 ---------------\n",
      "Val accuracy: 20.5%, Val avg loss: 3.628252 \n",
      "\n",
      "------------ Epoch 136 ---------------\n",
      "Val accuracy: 18.5%, Val avg loss: 3.712431 \n",
      "\n",
      "------------ Epoch 137 ---------------\n",
      "Val accuracy: 20.8%, Val avg loss: 3.598820 \n",
      "\n",
      "------------ Epoch 138 ---------------\n",
      "Val accuracy: 19.2%, Val avg loss: 3.658147 \n",
      "\n",
      "------------ Epoch 139 ---------------\n",
      "Val accuracy: 18.7%, Val avg loss: 3.675013 \n",
      "\n",
      "------------ Epoch 140 ---------------\n",
      "Val accuracy: 19.4%, Val avg loss: 3.665519 \n",
      "\n",
      "------------ Epoch 141 ---------------\n",
      "Val accuracy: 19.1%, Val avg loss: 3.701098 \n",
      "\n",
      "------------ Epoch 142 ---------------\n",
      "Val accuracy: 19.7%, Val avg loss: 3.668636 \n",
      "\n",
      "------------ Epoch 143 ---------------\n",
      "Val accuracy: 21.2%, Val avg loss: 3.589719 \n",
      "\n",
      "------------ Epoch 144 ---------------\n",
      "Val accuracy: 18.9%, Val avg loss: 3.704035 \n",
      "\n",
      "------------ Epoch 145 ---------------\n",
      "Val accuracy: 19.2%, Val avg loss: 3.698788 \n",
      "\n",
      "------------ Epoch 146 ---------------\n",
      "Val accuracy: 19.6%, Val avg loss: 3.643229 \n",
      "\n",
      "------------ Epoch 147 ---------------\n",
      "Val accuracy: 20.1%, Val avg loss: 3.648882 \n",
      "\n",
      "------------ Epoch 148 ---------------\n",
      "Val accuracy: 18.6%, Val avg loss: 3.685590 \n",
      "\n",
      "------------ Epoch 149 ---------------\n",
      "Val accuracy: 18.5%, Val avg loss: 3.729549 \n",
      "\n",
      "------------ Epoch 150 ---------------\n",
      "Val accuracy: 18.3%, Val avg loss: 3.660704 \n",
      "\n",
      "------------ Epoch 151 ---------------\n",
      "Val accuracy: 20.7%, Val avg loss: 3.599786 \n",
      "\n",
      "------------ Epoch 152 ---------------\n",
      "Val accuracy: 16.3%, Val avg loss: 3.757542 \n",
      "\n",
      "------------ Epoch 153 ---------------\n",
      "Val accuracy: 18.6%, Val avg loss: 3.665214 \n",
      "\n",
      "------------ Epoch 154 ---------------\n",
      "Val accuracy: 18.1%, Val avg loss: 3.709025 \n",
      "\n",
      "------------ Epoch 155 ---------------\n",
      "Val accuracy: 19.6%, Val avg loss: 3.653262 \n",
      "\n",
      "------------ Epoch 156 ---------------\n",
      "Val accuracy: 18.9%, Val avg loss: 3.663764 \n",
      "\n",
      "------------ Epoch 157 ---------------\n",
      "Val accuracy: 20.8%, Val avg loss: 3.627989 \n",
      "\n",
      "------------ Epoch 158 ---------------\n",
      "Val accuracy: 20.0%, Val avg loss: 3.643030 \n",
      "\n",
      "------------ Epoch 159 ---------------\n",
      "Val accuracy: 19.4%, Val avg loss: 3.674167 \n",
      "\n",
      "------------ Epoch 160 ---------------\n",
      "Val accuracy: 19.3%, Val avg loss: 3.632239 \n",
      "\n",
      "------------ Epoch 161 ---------------\n",
      "Val accuracy: 16.4%, Val avg loss: 3.713650 \n",
      "\n",
      "------------ Epoch 162 ---------------\n",
      "Val accuracy: 20.3%, Val avg loss: 3.645313 \n",
      "\n",
      "------------ Epoch 163 ---------------\n",
      "Val accuracy: 14.2%, Val avg loss: 3.872891 \n",
      "\n",
      "------------ Epoch 164 ---------------\n",
      "Val accuracy: 19.4%, Val avg loss: 3.677235 \n",
      "\n",
      "------------ Epoch 165 ---------------\n",
      "Val accuracy: 16.8%, Val avg loss: 3.799990 \n",
      "\n",
      "------------ Epoch 166 ---------------\n",
      "Val accuracy: 20.8%, Val avg loss: 3.614991 \n",
      "\n",
      "------------ Epoch 167 ---------------\n",
      "Val accuracy: 20.1%, Val avg loss: 3.631307 \n",
      "\n",
      "------------ Epoch 168 ---------------\n",
      "Val accuracy: 20.6%, Val avg loss: 3.618361 \n",
      "\n",
      "------------ Epoch 169 ---------------\n",
      "Val accuracy: 21.3%, Val avg loss: 3.608370 \n",
      "\n",
      "------------ Epoch 170 ---------------\n",
      "Val accuracy: 17.8%, Val avg loss: 3.728688 \n",
      "\n",
      "------------ Epoch 171 ---------------\n",
      "Val accuracy: 21.4%, Val avg loss: 3.613080 \n",
      "\n",
      "------------ Epoch 172 ---------------\n",
      "Val accuracy: 20.2%, Val avg loss: 3.663594 \n",
      "\n",
      "------------ Epoch 173 ---------------\n",
      "Val accuracy: 20.8%, Val avg loss: 3.610246 \n",
      "\n",
      "------------ Epoch 174 ---------------\n",
      "Val accuracy: 13.7%, Val avg loss: 3.840864 \n",
      "\n",
      "------------ Epoch 175 ---------------\n",
      "Val accuracy: 17.7%, Val avg loss: 3.794223 \n",
      "\n",
      "------------ Epoch 176 ---------------\n",
      "Val accuracy: 21.9%, Val avg loss: 3.573749 \n",
      "\n",
      "------------ Epoch 177 ---------------\n",
      "Val accuracy: 18.0%, Val avg loss: 3.710851 \n",
      "\n",
      "------------ Epoch 178 ---------------\n",
      "Val accuracy: 19.3%, Val avg loss: 3.660707 \n",
      "\n",
      "------------ Epoch 179 ---------------\n",
      "Val accuracy: 18.7%, Val avg loss: 3.693497 \n",
      "\n",
      "------------ Epoch 180 ---------------\n",
      "Val accuracy: 18.4%, Val avg loss: 3.724939 \n",
      "\n",
      "------------ Epoch 181 ---------------\n",
      "Val accuracy: 20.6%, Val avg loss: 3.582032 \n",
      "\n",
      "------------ Epoch 182 ---------------\n",
      "Val accuracy: 14.6%, Val avg loss: 4.021929 \n",
      "\n",
      "------------ Epoch 183 ---------------\n",
      "Val accuracy: 18.7%, Val avg loss: 3.725533 \n",
      "\n",
      "------------ Epoch 184 ---------------\n",
      "Val accuracy: 19.5%, Val avg loss: 3.632054 \n",
      "\n",
      "------------ Epoch 185 ---------------\n",
      "Val accuracy: 18.1%, Val avg loss: 3.732951 \n",
      "\n",
      "------------ Epoch 186 ---------------\n",
      "Val accuracy: 19.8%, Val avg loss: 3.635117 \n",
      "\n",
      "------------ Epoch 187 ---------------\n",
      "Val accuracy: 20.8%, Val avg loss: 3.597279 \n",
      "\n",
      "------------ Epoch 188 ---------------\n",
      "Val accuracy: 20.5%, Val avg loss: 3.626156 \n",
      "\n",
      "------------ Epoch 189 ---------------\n",
      "Val accuracy: 15.9%, Val avg loss: 3.831592 \n",
      "\n",
      "------------ Epoch 190 ---------------\n",
      "Val accuracy: 20.8%, Val avg loss: 3.622963 \n",
      "\n",
      "------------ Epoch 191 ---------------\n",
      "Val accuracy: 16.7%, Val avg loss: 3.748668 \n",
      "\n",
      "------------ Epoch 192 ---------------\n",
      "Val accuracy: 15.7%, Val avg loss: 4.003669 \n",
      "\n",
      "------------ Epoch 193 ---------------\n",
      "Val accuracy: 20.9%, Val avg loss: 3.593832 \n",
      "\n",
      "------------ Epoch 194 ---------------\n",
      "Val accuracy: 14.4%, Val avg loss: 3.831594 \n",
      "\n",
      "------------ Epoch 195 ---------------\n",
      "Val accuracy: 17.8%, Val avg loss: 3.659039 \n",
      "\n",
      "------------ Epoch 196 ---------------\n",
      "Val accuracy: 16.6%, Val avg loss: 3.735774 \n",
      "\n",
      "------------ Epoch 197 ---------------\n",
      "Val accuracy: 19.7%, Val avg loss: 3.636435 \n",
      "\n",
      "------------ Epoch 198 ---------------\n",
      "Val accuracy: 18.2%, Val avg loss: 3.763690 \n",
      "\n",
      "------------ Epoch 199 ---------------\n",
      "Val accuracy: 20.5%, Val avg loss: 3.651293 \n",
      "\n",
      "------------ Epoch 200 ---------------\n",
      "Val accuracy: 16.1%, Val avg loss: 3.817949 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for t in range(epochs):\n",
    "    print(f\"------------ Epoch {t+1} ---------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    valid(val_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
